import matplotlib.pyplot as plt  
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np  
from sklearn.cluster import KMeans  


# In[2]:


pip install matplotlib


# In[3]:


import sys
get_ipython().system('{sys.executable} -m pip install matplotlib')


# In[4]:


import matplotlib.pyplot as plt  
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np  
from sklearn.cluster import KMeans 


# In[5]:


import sys
get_ipython().system('{sys.executable} -m pip install scikit')


# In[6]:


pip install --upgrade pip


# In[7]:


import sys
get_ipython().system('{sys.executable} -m pip install --upgrade pip')


# In[8]:


import sys
get_ipython().system('{sys.executable} -m pip install scikit-learn')


# In[9]:


import matplotlib.pyplot as plt  
get_ipython().run_line_magic('matplotlib', 'inline')
import numpy as np  
from sklearn.cluster import KMeans 


# In[10]:


my_data = np.loadtxt("3dV.TsujiiData.csv",skiprows=1,delimiter=",")


# In[11]:


my_data


# In[12]:


kmeans = KMeans(n_clusters=7, random_state = 0).fit(my_data)
kmeans.predict(my_data)
#randomstate allows us to perform the same initialization every time


# In[13]:


davidsgenders = np.loadtxt("davidsgenders.csv",skiprows=1,delimiter=",")
captiveborn = np.loadtxt("captiveborn.csv", skiprows=1, delimiter=",")
davidsfemales = np.loadtxt("davidsfemales.csv",skiprows=1,delimiter=",")
davidsmales = np.loadtxt("davidsmales.csv",skiprows=1,delimiter=",")


# In[14]:


kmeans.cluster_centers_



# In[15]:


labels = kmeans.labels_
labels_list = labels.tolist()
for x in range(0,max(labels_list)+1):
    print (x, labels_list.count(x))
    
    

    
def datapoints_for_label(label, alldata):
    clusters = np.ndarray((0,3)) # initialize cluster for LABEL to an empty 3 column matrix
    # loop over all labels, find the ones matching LABEL, collect corresponding datapoint into array
    for i in range(0,len(labels_list)):  
        # the LABEL for datapoint i
        plabel = labels_list[i]  
        # datapoint i
        datapoint = alldata[i]
        if plabel == label:   # does this point's label match LABEL?
            # append datapoint i to cluster for LABEL
            clusters = np.append(clusters, [datapoint], axis=0)  
    return clusters




# for each label, compute the average value, by column, of data points which have that label
for label in range(0, max(labels_list)+1):
    cluster = datapoints_for_label(label,my_data)
    print('label', label, 'mean', cluster.mean(axis=0))
    print('label', label, 'min', cluster.min(axis=0))
    print('label', label, 'max', cluster.max(axis=0))
    print('label', label, 'std', cluster.std(axis=0))

    
centroids = np.array([[0.41839286, 0.32628571, 0.06302381], 
             [1.58086792, 0.91274528, 0.22564057], 
             [1.07774242, 0.63221212, 0.12128788],
             [1.98298571, 1.15351429, 0.2109],
             [0.68657547, 0.42679245, 0.06823585],
             [1.21359375, 0.71072396, 0.13283333],
             [0.86298876, 0.5171236, 0.06844944]]) 




# In[16]:


import numpy as np
import matplotlib.pyplot as plt
# Though the following import is not directly being used, it is required
# for 3D projection to work
from mpl_toolkits.mplot3d import Axes3D

from sklearn.cluster import KMeans
from sklearn import datasets


# In[17]:


from sklearn.cluster import KMeans
import matplotlib.pyplot as plt




# Scaling the data to normalize
#labels = KMeans(n_clusters=7, random_state = 0).fit_predict(my_data)
genders = KMeans(n_clusters=7, init = centroids).fit(davidsgenders)
captive = KMeans(n_clusters=7, init = centroids).fit(captiveborn)

# Visualize it:
plt.figure(figsize=(8, 5),dpi=300)
plt.scatter(my_data[:,0], my_data[:,1], c=kmeans.labels_.astype(float))
#plt.scatter(davidsfemales[:,0], davidsfemales[:,1], color = "red")
#plt.scatter(davidsmales[:,0], davidsmales[:,1], color = "blue")
#plt.scatter(davidsgenders[:,0],davidsgenders[:,1], c=genders.labels_.astype(float),)
#plt.scatter(captiveborn[:,0],captiveborn[:,1],c=captive.labels_.astype(float))
plt.xlabel('Length (mm)')
plt.ylabel('Height (mm)')


# In[18]:


#z = np.array([[1,2]])
#model.predict(z)


# In[19]:


z = np.array([[1.204 , 0.687 , 0.153 ],
       [1.248 , 0.741 , 0.14  ]])
r = kmeans.predict(z)
r


# In[20]:


model.labels_.astype(float)


# In[ ]:


labels


# In[ ]:


cluster = datapoints_for_label(3,my_data)
cluster


# In[ ]:


plt.figure(figsize=(8, 5))
plt.scatter(my_data[:,0], my_data[:,1], c=kmeans.labels_.astype(float))


# In[23]:


import sklearn
mms = sklearn.preprocessing.MinMaxScaler()
mms.fit(my_data)
data_transformed = mms.transform(my_data)


# In[37]:


Sum_of_squared_distances = []
K = range(6,10)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(my_data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()


